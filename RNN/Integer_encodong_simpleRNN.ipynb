{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DaSSg29--e1"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = ['Apoorva Ranjeet is ok',\n",
        "              'Aadrika is learning gaming stuffs',\n",
        "              'Anusha managing finance of wellsfargo',\n",
        "              'Nmari started her journey to become a doctor',\n",
        "              'Barbie is more mature compared to last time',\n",
        "              'Sweety is getting comfortable with social media these days',\n",
        "              'Anjali as usual living her best and enjoying the food the most']"
      ],
      "metadata": {
        "id": "-ZzuHE1F_Ikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will tokenize the data , meaning removal of the special symbols, separating each word,converting capital letters word into small letters etc."
      ],
      "metadata": {
        "id": "RAII7-IbA4Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token='akku') # oov stands for out of vocabulary this parameter replacse the new word which is not in the data with the word we pass in this parameter like akku"
      ],
      "metadata": {
        "id": "WejKF4rPAsSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(input_data)"
      ],
      "metadata": {
        "id": "g8LoIvnSBzvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# theres an attribute name word_index this is used to check the index given by the tokenizer to the words of your data and also checks the number of unique words in the data\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnhBOwDMCDgd",
        "outputId": "9e4c166d-ab73-431b-c731-e653889d512a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'akku': 1,\n",
              " 'is': 2,\n",
              " 'her': 3,\n",
              " 'to': 4,\n",
              " 'the': 5,\n",
              " 'apoorva': 6,\n",
              " 'ranjeet': 7,\n",
              " 'ok': 8,\n",
              " 'aadrika': 9,\n",
              " 'learning': 10,\n",
              " 'gaming': 11,\n",
              " 'stuffs': 12,\n",
              " 'anusha': 13,\n",
              " 'managing': 14,\n",
              " 'finance': 15,\n",
              " 'of': 16,\n",
              " 'wellsfargo': 17,\n",
              " 'nmari': 18,\n",
              " 'started': 19,\n",
              " 'journey': 20,\n",
              " 'become': 21,\n",
              " 'a': 22,\n",
              " 'doctor': 23,\n",
              " 'barbie': 24,\n",
              " 'more': 25,\n",
              " 'mature': 26,\n",
              " 'compared': 27,\n",
              " 'last': 28,\n",
              " 'time': 29,\n",
              " 'sweety': 30,\n",
              " 'getting': 31,\n",
              " 'comfortable': 32,\n",
              " 'with': 33,\n",
              " 'social': 34,\n",
              " 'media': 35,\n",
              " 'these': 36,\n",
              " 'days': 37,\n",
              " 'anjali': 38,\n",
              " 'as': 39,\n",
              " 'usual': 40,\n",
              " 'living': 41,\n",
              " 'best': 42,\n",
              " 'and': 43,\n",
              " 'enjoying': 44,\n",
              " 'food': 45,\n",
              " 'most': 46}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to check the frequency of each word in the data\n",
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdr0MihtCeuk",
        "outputId": "bce28911-cba5-452f-9808-9c1b58c1f4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('apoorva', 1),\n",
              "             ('ranjeet', 1),\n",
              "             ('is', 4),\n",
              "             ('ok', 1),\n",
              "             ('aadrika', 1),\n",
              "             ('learning', 1),\n",
              "             ('gaming', 1),\n",
              "             ('stuffs', 1),\n",
              "             ('anusha', 1),\n",
              "             ('managing', 1),\n",
              "             ('finance', 1),\n",
              "             ('of', 1),\n",
              "             ('wellsfargo', 1),\n",
              "             ('nmari', 1),\n",
              "             ('started', 1),\n",
              "             ('her', 2),\n",
              "             ('journey', 1),\n",
              "             ('to', 2),\n",
              "             ('become', 1),\n",
              "             ('a', 1),\n",
              "             ('doctor', 1),\n",
              "             ('barbie', 1),\n",
              "             ('more', 1),\n",
              "             ('mature', 1),\n",
              "             ('compared', 1),\n",
              "             ('last', 1),\n",
              "             ('time', 1),\n",
              "             ('sweety', 1),\n",
              "             ('getting', 1),\n",
              "             ('comfortable', 1),\n",
              "             ('with', 1),\n",
              "             ('social', 1),\n",
              "             ('media', 1),\n",
              "             ('these', 1),\n",
              "             ('days', 1),\n",
              "             ('anjali', 1),\n",
              "             ('as', 1),\n",
              "             ('usual', 1),\n",
              "             ('living', 1),\n",
              "             ('best', 1),\n",
              "             ('and', 1),\n",
              "             ('enjoying', 1),\n",
              "             ('the', 2),\n",
              "             ('food', 1),\n",
              "             ('most', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to check the number of rows in the document\n",
        "tokenizer.document_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1percjiDKsW",
        "outputId": "1337ba9a-bb9c-41ee-fa2a-62125327832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So step 1 is completed we have sucessfully given the index to the words of data now second step is generate sequence"
      ],
      "metadata": {
        "id": "D6CWvI-8Dfp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(input_data)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvDpd3JKDZvu",
        "outputId": "d321c383-baa2-4c5f-fd86-7c88430a0931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 7, 2, 8],\n",
              " [9, 2, 10, 11, 12],\n",
              " [13, 14, 15, 16, 17],\n",
              " [18, 19, 3, 20, 4, 21, 22, 23],\n",
              " [24, 2, 25, 26, 27, 4, 28, 29],\n",
              " [30, 2, 31, 32, 33, 34, 35, 36, 37],\n",
              " [38, 39, 40, 41, 3, 42, 43, 44, 5, 45, 5, 46]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now the size of these squences are of different size so we have to do padding"
      ],
      "metadata": {
        "id": "rAXRqca-EW0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "LtpJryb9EOw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences,padding='post')"
      ],
      "metadata": {
        "id": "tgd8NABsE6NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "id": "m6nR11gbFS6Y",
        "outputId": "ea02fb44-51d1-49de-add1-fd7a550f6b38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  7,  2,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 9,  2, 10, 11, 12,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [13, 14, 15, 16, 17,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [18, 19,  3, 20,  4, 21, 22, 23,  0,  0,  0,  0],\n",
              "       [24,  2, 25, 26, 27,  4, 28, 29,  0,  0,  0,  0],\n",
              "       [30,  2, 31, 32, 33, 34, 35, 36, 37,  0,  0,  0],\n",
              "       [38, 39, 40, 41,  3, 42, 43, 44,  5, 45,  5, 46]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MV5-dUjFVad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}