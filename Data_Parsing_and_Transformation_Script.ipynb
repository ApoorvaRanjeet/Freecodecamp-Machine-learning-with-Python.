{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install xmltodict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NdOca2eXvE4",
        "outputId": "9a138dca-3683-4ef4-e1a2-ad4b938551d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import xmltodict\n",
        "\n",
        "def parse_csv_data(filepath):\n",
        "    # Read CSV data into a Pandas DataFrame\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # Standardize column names and data types\n",
        "    df.columns = [standardize_column_name(col) for col in df.columns]\n",
        "    for col in df.columns:\n",
        "        df[col].fillna('-', inplace=True)\n",
        "\n",
        "    return df.to_dict('records')\n",
        "\n",
        "def parse_json_data(filepath):\n",
        "    # Read JSON data into a Python dictionary\n",
        "    with open(filepath) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Standardize data structure and values\n",
        "    standardized_data = standardize_json_data(data)\n",
        "\n",
        "    return standardized_data\n",
        "\n",
        "def parse_xml_data(filepath):\n",
        "    # Convert XML data to a Python dictionary\n",
        "    with open(filepath) as f:\n",
        "        xml_data = f.read()\n",
        "\n",
        "    dict_data = xmltodict.parse(xml_data)\n",
        "\n",
        "    # Standardize data structure and values\n",
        "    standardized_data = standardize_xml_data(dict_data)\n",
        "\n",
        "    return standardized_data\n",
        "\n",
        "def standardize_column_name(column_name):\n",
        "    # Replace spaces and special characters with underscores\n",
        "    column_name = column_name.lower().replace(' ', '_')\n",
        "    column_name = column_name.replace('-', '_')\n",
        "\n",
        "    return column_name\n",
        "\n",
        "def standardize_json_data(data):\n",
        "    # Recursively standardize data structure and values\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "            standardized_key = standardize_column_name(key)\n",
        "            if isinstance(value, list):\n",
        "                value = [standardize_json_data(item) for item in value]\n",
        "            elif isinstance(value, dict):\n",
        "                value = standardize_json_data(value)\n",
        "            data[standardized_key] = value\n",
        "    elif isinstance(data, list):\n",
        "        for i, item in enumerate(data):\n",
        "            data[i] = standardize_json_data(item)\n",
        "\n",
        "    return data\n",
        "\n",
        "def standardize_xml_data(data):\n",
        "    # Recursively standardize data structure and values\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "            if isinstance(value, list):\n",
        "                data[key] = [standardize_xml_data(item) for item in value]\n",
        "            elif isinstance(value, dict):\n",
        "                data[key] = standardize_xml_data(value)\n",
        "\n",
        "    return data\n",
        "\n",
        "def parse_and_transform_data(filepath, format):\n",
        "    if format == 'csv':\n",
        "        parsed_data = parse_csv_data('/content/healthcare_dataset.csv')\n",
        "    # elif format == 'json':\n",
        "    #     parsed_data = parse_json_data(filepath)\n",
        "    # elif format == 'xml':\n",
        "    #     parsed_data = parse_xml_data(filepath)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported data format: {format}\")\n",
        "\n",
        "    return parsed_data\n"
      ],
      "metadata": {
        "id": "VsUfDjyiP_qI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = parse_and_transform_data('/content/healthcare_dataset.csv', format='csv')"
      ],
      "metadata": {
        "id": "L0z8JinQYW1R"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the standardized data here\n",
        "print(parsed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Lu2z3WYXQH",
        "outputId": "5db7cb6f-401e-40a9-e870-dc2731176315"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def store_parsed_data(data, filepath):\n",
        "  with open(filepath, 'w') as json_file:\n",
        "    json.dump(data, json_file, indent=4)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "parsed_data = parse_and_transform_data('/content/healthcare_dataset.csv', 'csv')\n",
        "store_parsed_data(parsed_data, '/content/untitled.json')\n"
      ],
      "metadata": {
        "id": "Lk0Wrul0YhZw"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}